{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba5ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ea6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "# Over every single \n",
    "def polyline_to_trip_duration(polyline):\n",
    "  return max(polyline.count(\"[\") - 2, 0) * 15\n",
    "\n",
    "df_tr[\"LEN\"] = df_tr[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
    "\n",
    "gps_location_df = pd.read_csv('metaData_taxistandsID_name_GPSlocation.csv')\n",
    "\n",
    "# Create a dictionary for each ORIGIN_STAND, where key is the stand id and value is a dic (Latitude, Longitude)\n",
    "location_dict = gps_location_df.set_index('ID')[['Latitude', 'Longitude']].T.apply(tuple).to_dict()\n",
    "\n",
    "df_tr['Latitude'] = df_tr['ORIGIN_STAND'].map(lambda x: location_dict.get(x, {}).get('Latitude', np.nan))\n",
    "df_tr['Longitude'] = df_tr['ORIGIN_STAND'].map(lambda x: location_dict.get(x, {}).get('Longitude', np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad00eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_public.csv\")\n",
    "\n",
    "taxi_test_ids = []\n",
    "\n",
    "for id in df_test[\"TAXI_ID\"]:\n",
    "    if id not in taxi_test_ids:\n",
    "        taxi_test_ids.append(id)\n",
    "        \n",
    "taxi_test_ids_dic = {}\n",
    "for ele in taxi_test_ids:\n",
    "    taxi_test_ids_dic[ele] = ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90f8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tr.sort_values('TIMESTAMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4dfcb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[int(len(df)*6/7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db711d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORIGIN_CALL'].fillna(0, inplace=True)\n",
    "df['ORIGIN_STAND'].fillna(0, inplace=True)\n",
    "df['Latitude'].fillna(0, inplace=True)\n",
    "df['Longitude'].fillna(0, inplace=True)\n",
    "df = df[df['MISSING_DATA'] != True]\n",
    "df['TAXI_ID'] = df['TAXI_ID'].map(lambda x: taxi_test_ids_dic.get(x, 0))\n",
    "\n",
    "# assuming your dataframe is named df\n",
    "categorical_features = ['CALL_TYPE', 'TAXI_ID']\n",
    "spatial_features = ['Latitude', 'Longitude']\n",
    "temporal_feature = 'TIMESTAMP'\n",
    "\n",
    "# Preprocessing categorical features\n",
    "label_encoders = {}\n",
    "n_cats = {}\n",
    "\n",
    "for cat in categorical_features:\n",
    "    label_encoders[cat] = LabelEncoder()\n",
    "    df[cat] = label_encoders[cat].fit_transform(df[cat])\n",
    "    n_cats[cat] = len(label_encoders[cat].classes_)\n",
    "\n",
    "df[temporal_feature] = MinMaxScaler().fit_transform(df[temporal_feature].values.reshape(-1,1))\n",
    "\n",
    "df[spatial_features] = MinMaxScaler().fit_transform(df[spatial_features])\n",
    "\n",
    "\n",
    "embedding1 = nn.Embedding(df['CALL_TYPE'].nunique(), 50)\n",
    "embedding2 = nn.Embedding(df['TAXI_ID'].nunique(), 50)\n",
    "\n",
    "class CombinedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, n_cats):\n",
    "        super(CombinedRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define embeddings for each categorical feature\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(n_cats[cat], 50) for cat in categorical_features])\n",
    "        self.fc_spatial = nn.Linear(2, 64)\n",
    "\n",
    "        # Define LSTM layer\n",
    "        self.rnn = nn.LSTM(input_size + len(categorical_features) * 50 + 64, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define output layer\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x, cat_features, spatial_features):\n",
    "        # Embedding categorical features\n",
    "        embeds = [emb(cat_features[:, :, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embeds = torch.cat(embeds, -1)\n",
    "\n",
    "        # Process spatial features\n",
    "        spatial_features = self.fc_spatial(spatial_features)\n",
    "\n",
    "        x = x.unsqueeze(2)\n",
    "        x_combined = torch.cat((x, embeds, spatial_features), dim=2)\n",
    "\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x_combined.size(0), self.hidden_size).to(x_combined.device)\n",
    "        c0 = torch.zeros(self.num_layers, x_combined.size(0), self.hidden_size).to(x_combined.device)\n",
    "\n",
    "        # Forward propagate the LSTM\n",
    "        out, _ = self.rnn(x_combined, (h0, c0))\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 1  # as we only have 'TIMESTAMP' as input\n",
    "hidden_size = 32\n",
    "output_size = 1  # as regression predicts a single value\n",
    "num_layers = 2\n",
    "\n",
    "model = CombinedRNN(input_size, hidden_size, output_size, num_layers, n_cats)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a306bcaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m spatial_tensor \u001b[38;5;241m=\u001b[39m spatial_tensor\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m CombinedRNN(input_size, hidden_size, output_size, num_layers, n_cats, \u001b[43membedding_dim\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Define your loss function and optimizer\u001b[39;00m\n\u001b[0;32m     25\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare your data\n",
    "temporal_tensor = torch.tensor(df[temporal_feature].values).float()\n",
    "categorical_tensor = torch.tensor(df[categorical_features].values).long()\n",
    "spatial_tensor = torch.tensor(df[spatial_features].values).float()\n",
    "\n",
    "outputs = torch.tensor(df['LEN'].values).float()\n",
    "\n",
    "# You need to adjust dimensions according to your actual batch size\n",
    "temporal_tensor = temporal_tensor.unsqueeze(0)\n",
    "categorical_tensor = categorical_tensor.unsqueeze(0)\n",
    "spatial_tensor = spatial_tensor.unsqueeze(0)\n",
    "outputs = outputs.unsqueeze(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "temporal_tensor = temporal_tensor.float().to(device)\n",
    "categorical_tensor = categorical_tensor.long().to(device)\n",
    "spatial_tensor = spatial_tensor.float().to(device)\n",
    "\n",
    "outputs = outputs.to(device)\n",
    "\n",
    "model = CombinedRNN(input_size, hidden_size, output_size, num_layers, n_cats, embedding_dim).to(device)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    preds = model(temporal_tensor, categorical_tensor, spatial_tensor)\n",
    "    print(\"Shape of Model Output: \", preds.shape)\n",
    "    print(\"Shape of Target Tensor: \", outputs.shape)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(preds, outputs)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17def4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_TF_Sklearn_Kernel",
   "language": "python",
   "name": "tf_sklearn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
